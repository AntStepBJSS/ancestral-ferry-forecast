import requests
from dotenv import load_dotenv
import os
from dataclasses import dataclass

API_DATETIME_FILTER_START = "2025-06-04T13:00:00Z"
FORECAST_BASE_DATETIME_FOR_MATCH = "2025-06-04T"
FORECAST_TIME_FOR_MATCH = "2025-06-08T13"


@dataclass
class WindItem:
    item_id: str
    file_name: str
    standard_name: str
    long_name: str
    forecast_reference_time: str
    forecast_time_for: str


item_id_check_list = []
filter_to_wind_items: list[WindItem] = []


def main():
    load_dotenv()
    api_key = os.getenv("API_KEY")
    base_url = "https://gateway.api-management.metoffice.cloud/blended-probabilistic-forecast-object-svc/1.0.0"
    full_url = f"{base_url}/collections/uk-gridded-percentiles/items"
    datetime_filter_for_url = f"datetime={API_DATETIME_FILTER_START}/.."
    url_filtered_on_date_time = f"{full_url}?{datetime_filter_for_url}"
    headers = {"accept": "*/*", "apikey": api_key}
    response = requests.get(url_filtered_on_date_time, headers=headers).json()

    page = 1

    filter_wind_items(response)

    next_page_token = response.get("next_page_token")
    while next_page_token:
        print(f"\rPages: {page}", end="", flush=True)
        page += 1
        url_next = f"{full_url}?token={next_page_token}&{datetime_filter_for_url}"
        response = requests.get(url_next, headers=headers).json()
        duplicate_item = filter_wind_items(response)
        next_page_token = response.get("next_page_token")
        if duplicate_item:
            print("Duplicate items found, stopping further processing.")
            break

    # Search for wind_from_direction in standard_name in content_metadata within items
    for wind_item in filter_to_wind_items:
        if wind_item.standard_name == "wind_from_direction":
            print(f"Downloading wind_from_direction in file: {wind_item.file_name}")
            download_wind_item(
                full_url, headers, wind_item.item_id, wind_item.file_name
            )
        if wind_item.standard_name == "wind_speed":
            print(f"Downloading wind_speed in file: {wind_item.file_name}")
            download_wind_item(
                full_url, headers, wind_item.item_id, wind_item.file_name
            )


def filter_wind_items(response) -> bool:
    items = response["items"]
    for item in items:
        item_id_match = item["file_metadata"].get("item_id", "")
        if item_id_match in item_id_check_list:
            print(f"Jumping out item with duplicate item_id: {item_id_match}")
            return True
        item_id_check_list.append(item_id_match)
        content_metadata = item.get("content_metadata", [])
        file_metadata = item.get("file_metadata", {})
        for metadata in content_metadata:
            name = metadata.get("standard_name", "") + metadata.get("long_name", "")
            # print(f"\rName: {name}")

            if "wind_speed" == name or "wind_direction" in name:
                wind_item = WindItem(
                    item_id=file_metadata.get("item_id", ""),
                    file_name=file_metadata.get("file_name", ""),
                    standard_name=metadata.get("standard_name", ""),
                    long_name=metadata.get("long_name", ""),
                    forecast_reference_time=metadata.get("forecast_reference_time", ""),
                    forecast_time_for=metadata.get("time", [""])[0],
                )
                #Maybe convert to a real date and use greater than??
                if wind_item.forecast_reference_time.startswith(
                    FORECAST_BASE_DATETIME_FOR_MATCH
                ) and wind_item.forecast_time_for.startswith(FORECAST_TIME_FOR_MATCH):
                    print(
                        f" Found wind item: {wind_item.standard_name} for {wind_item.forecast_time_for} forecasted at {wind_item.forecast_reference_time}"
                    )
                    filter_to_wind_items.append(wind_item)
    return False


def download_wind_item(url, headers, item_id, file_name):
    item_url = f"{url}/{item_id}"
    url_response = requests.get(item_url, headers=headers).url
    download_response = requests.get(url_response, stream=True)
    if download_response.ok:
        file_location_and_name = f"downloads/{file_name}"
        with open(file_location_and_name, "wb") as f:
            f.write(download_response.content)


if __name__ == "__main__":
    main()
